---
bibliography: references.bib
output:
  pdf_document:
    keep_tex: true
csl: asm.csl
geometry: margin=1.0in
header-includes:
 - \usepackage{upgreek}
 - \usepackage{booktabs}
 - \usepackage{longtable}
 - \usepackage{graphicx}
 - \usepackage{array}
 - \usepackage{multirow}
 - \usepackage{wrapfig}
 - \usepackage{float}
 - \usepackage{colortbl}
 - \usepackage{pdflscape}
 - \usepackage{tabu}
 - \usepackage{threeparttable}
 - \usepackage{threeparttablex}
 - \usepackage[normalem]{ulem}
 - \usepackage{makecell}
 - \usepackage{setspace}
 - \doublespacing
 - \usepackage[left]{lineno}
 - \linenumbers
 - \modulolinenumbers
 - \usepackage{helvet} % Helvetica font
 - \renewcommand*\familydefault{\sfdefault} % Use the sans serif version of the font
 - \usepackage[T1]{fontenc}
 - \usepackage[shortcuts]{extdash}
---


```{r, echo=FALSE}
options(tidyverse.quiet = TRUE)
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(kableExtra))
suppressPackageStartupMessages(library(glue))

opts_chunk$set("tidy" = TRUE)
opts_chunk$set("echo" = FALSE)
opts_chunk$set("eval" = TRUE)
opts_chunk$set("warning" = FALSE)
opts_chunk$set("message" = FALSE)
opts_chunk$set("cache" = FALSE)

inline_hook <- function(x, digits=2){

  if(is.list(x)){
    x <- unlist(x)
  }
  if(is.numeric(x)){
      paste(format(x,big.mark=',', digits=digits, nsmall=digits, scientific=FALSE))
  } else {
      paste(x)
  }
}
knitr::knit_hooks$set(inline=inline_hook)

package_version <- function(package){

  paste(unlist(packageVersion(package)), collapse='.')

}


oxford_comma <- function(x, digits=2) {

  x <- map_chr(x, inline_hook, digits=digits)

  if(length(x) < 2){
    x
  } else if(length(x) == 2){
    paste(x, collapse = " and ")
  } else {
    paste(paste(x[-length(x)], collapse=", "), x[length(x)], sep=", and ")
  }
}

capitalize <- function(string) {
  substr(string, 1, 1) <- toupper(substr(string, 1, 1))
  string
}


datasets <- c("bioethanol", "human", "lake", "marine", "mice", "peromyscus",
              "rainforest", "rice", "seagrass", "sediment", "soil", "stream")

pretty_datasets <- tibble(
  plain = datasets,
  pretty = capitalize(plain)
)


```

# Rarefy your data


\vspace{20mm}

**Running title:** Rarefy your data

\vspace{20mm}

Patrick D. Schloss${^\dagger}$

\vspace{40mm}

${\dagger}$ To whom corresponsdence should be addressed:


\href{mailto:pschloss@umich.edu}{pschloss@umich.edu}

Department of Microbiology & Immunology

University of Michigan

Ann Arbor, MI 48109

\vspace{20mm}

**Research article**

\newpage

```{r datasets}
table_1 <- read_tsv(here('data/process/study_summary_statistics.tsv'))

n_sample_range <- table_1 %>%
  pull(n_samples) %>%
  range() %>% as.integer()

n_med_sequence_range <- table_1 %>%
  pull(median) %>%
  range() %>% as.integer()

low_fold_samples <- table_1 %>%
  filter(fold_difference < 2) %>%
  pull(directory)

high_fold_range <- table_1 %>%
  filter(fold_difference >= 2) %>%
  pull(fold_difference) %>%
  range() %>%
  round(digits=1)
```


## Abstract



## Importance



\newpage

## Introduction

* Motivation
  * Problem of uneven sampling effort
* What is rarefaction? History, reason for rarefaction
  * Repeated down sampling of datasets to a common number of observations to calculate the average value to ascertain the expected value of a metric for the metric under study; typically richness
  * Control for unneven sampling effort
  * Methods vary in their sensitivity to uneven sampling
  * Compositional data analysis
* Reasons behind "rarefaction is inadmissable"
  * Weird simulation
* Alternative approaches and claims
  * sampling invariance
* Goal of this study

This analysis included 16S rRNA gene sequence data from from 12 studies that characterized the variation in bacterial communities from diverse environments (Table 1). The original studies generated the sequence data by pooling separate PCR products that were generated by amplifying the V4 region of the 16S rRNA gene from the bacterial DNA in multiple samples. Because pooling equimolar quantities of DNA is frought with difficulties, it was common to observe wide variation in the number of sequences in each sample (Table 1 and Figure S1).

## Results

***Without rarefaction, metrics of alpha diversity are sensitive to sampling effort.*** To test the sesitivity of various approaches of measuring alpha diversity to sampling effort, I generated null models for each dataset. Under a null model, each community from the same dataset would be expected to have the same alpha diversity regardless of the sampling effort. I measured the richness of the communities in each dataset without any correction, using scaled ranked subsampling (SRS) normalized OTU counts, with estimates based on non-parametric and parametric approaches, and using rarefaction (e.g. Figure S2). For each dataset, all of the approaches, except for rarefaction, showed a strong correlation between richness and the number of sequences in the sample (Figure 1A). Next, I assessed diversity using the Shannon diversity index and the inverse Simpson diversity index without any correction, using normalized OTU counts, and rarefaction; I also used a non-parametric estimator of Shannon diversity. The correlation between sampling depth and the diversity metric was not as strong as it was for richness and the inverse Simpson diversity values were less sensitive than the Shannon diversity values; however, the correlation to the rarefied diversity metrics were the lowest for all of the metrics and studies (Figure 1A). The rarefied alpha-diversity metrics consistently demonstrated a lack of sensitivity to sampling depth.


***Without rarefaction, metrics of beta diversity are sensitive to sampling effort.*** To test the sesitivity of various approaches of measuring beta diversity to sampling effort, I used the same null models used for studying the sensitivity of alpha diversity. Under a null model, the ecological distance between any pair of samples would be the same regardless of the difference in the number of sequences observed in each sample (e.g., Figure S3). First, I calculated the Jaccard distance coefficient between all pairs of communities within a dataset. The Jaccard distance coefficient is the fraction of OTUs that are unique to either community and does not account for the abundance of the OTUs. Jaccard distances were calcualted using the uncorrected OTU counts, with rarefaction, relative abundances, and following normalization using cumulative sum scaling (CSS) and SRS. Only the rarefied distances showed a lack of sensitivity to sampling effort (Figure 1B). Second, I analyzed the sensitivity of the Bray-Curtis distance coefficient, which is a popular metric that incorporates the abundance of each OTU. Similar to what I observed with the Jaccard coefficient, only the rarefied data showed a lack of sensitivity to sampling effort (Figure 1B). Third, I calcualted the Euclidean distance on raw OTU counts where the central log-ratio (CLR) was calculated (i.e., Aitchison distances) by ignoring OTUs in samples with zero counts (Robust CLR), adding a pseudocount of one to all OTU counts prior to calculating the CLR (One CLR), adding a pseudocount of one divided by the total number of sequences obtained for the community (Nudge CLR), and imputing the value of zero counts (Zero CLR). The Aitchison distances were all strongly sensitive to sampling effort (Figure 1B). Finally, I used the variance stabilization technique (VST) from DeSeq2 prior to calculating Euclidean distances. Again, there was a strong sensitivity to sampling effort (Figure 1B). Although Euclidean distances are not typically used on raw or rarefied count data in ecology, rarefied Euclidean distances were not sensitive to sampling effort. Across each of the beta diversity metrics and approaches used to account for uneven sampling effort and sparsity, rarefaction was the least sensitive approach to differences in sampling effort.


***Rarefaction limits the detection of false positives when sampling effort and treatment group are confounded.*** Next, I investigated the impact of the various strategies and metrics on falsely detecting a significant difference using the the same communities generated from the null model in the analysis of alpha and beta diversity metrics. To test for differences in alpha and beta diversity I used the non-parametric Wilcoxon test and non-parametric permutation-based multivariate analysis of variance (PERMANOVA). First, I employed an unbiased null treatment model to measure the false detection rate, which should not have meaningfully differed from 5%. Indeed, for each dataset and alpha and beta diversity metric and strategy for accounting for uneven sampling, approximately 5% of the tests yielded a significant result (Figure 2). Second, I employed a biased null treatment model where the treatment group was completely confounded with the number of sequences in each sample. Under this model, only the rarefied data consistently resulted in a 5% false positive rate for alpha and beta diversity metrics (Figure 2). These results aligned with the observed sensitivity of alpha and beta diversity metrics to sampling effort and underscore the value of rarefaction.


***Rarefaction preserves the statistical power to detect differences between treatment groups.*** To assess the impact of different approaches to control for uneven sampling effort I performed two additional simulations. In the first simulation, I implemented a skewed abundance distribution model to create two treatment groups for each datasets that were each populated with half of the samples each with the same number of sequences as the samples had in the observed data. The power to detect differences in richness between the two simulated treatment groups by all approaches was low (Figure 4A). This was likely because the approach for generating the perturbed community did not necessarily change the number of OTUs in each treatment group. Regardless, the simulations testing differencse in richness using the Rice and Stream datasets had the greatest power when the richness data were rarefied. To explore this further, a richness-adjusted community model was created by removing 3% of the OTUs from a null model model. As suggested by the first simulation, the rarefied richness data had a higher statistical power than the other approaches when measuring richness (Figure 5). The simulations testing the power to detect differences in Shannon diversity also showed that rarefied data performed other methods (Figure 4A). When testing for differences in the Inverse Simpson diversity index the the difference between rarefaction and the other methods was negligible (Figure 4A). For tests of beta diversity I found that rarefaction was the most reliable approach to maintain statistical power to detect differences between two communities. Among the tests using the Jaccard and Bray-Curtis metrics, raw count data and CSS normalized data had little power relative to rarefied, relative abundance, and SRS normalized data. The differences in power between rarefied, relative abundance, and SRS normalized data was small, but if there were differences, the power obtained using rarefied data was greater than the other methods. Among the tests using Euclidean distances, using raw counts and CLR and DeSeq2 transformed data had little power relative to the distances calcualted using rarefied and relative abundance data. This power-based analysis of the simulated communities using different methods of handling uneven sample sizes demonstrated the value of rarefaction for preserving the statistical power to detect differences between treatment groups for measures of alpha and beta diversity.


```{r coverage}
loss <- table_1 %>%
  select(nice_name, fold_difference) %>%
  mutate(loss = round(100* (1 - 1/fold_difference), 1)) %>%
  slice_max(loss)
  
obs_coverage_files <- glue("../data/{datasets}/data.otu.obs_coverage")
names(obs_coverage_files) <- datasets

obs_cor <- map_dfr(obs_coverage_files, read_tsv, .id = "dataset",
        col_types = cols(group = col_character(),
                         .default = col_double()))

obs_median <- obs_cor %>%
  group_by(dataset) %>%
  summarize(med = round(100 * median(norare_coverage), 1)) %>%
  arrange(med) %>%
  slice(c(1, n())) %>%
  mutate(med = format(med, 1))

rare_median <- obs_cor %>%
  group_by(dataset) %>%
  summarize(med = round(100 * median(rare_coverage), 1)) %>%
  arrange(med) %>%
  filter(med < 90)

rare_coverage_files <- glue("../data/{datasets}/data.otu.rarefy_coverage")
names(rare_coverage_files) <- datasets

cor_line <- map_dfr(rare_coverage_files, read_tsv, .id = "dataset",
        col_types = cols(.default = col_double()))

extrapolate <- cor_line %>%
  mutate(ninety = abs(mean - 0.90),
         ninetyfive = abs(mean - 0.95),
         ninetynine = abs(mean - 0.99)) %>%
  group_by(dataset) %>%
  summarize(ninety = nseqs[which.min(ninety)],
            ninetyfive = nseqs[which.min(ninetyfive)],
            ninetynine = nseqs[which.min(ninetynine)]) %>%
  mutate(ninetyfive = ninetyfive / ninety - 1,
         ninetynine = ninetynine / ninety - 1) %>%
  summarize(m = round(mean(ninetyfive), 1),
            n = round(mean(ninetynine), 1)
            )
```

***Increased rarefaction depth reduces intra-sample variation in alpha and beta diversity.*** Once concern with rarefying communities is the perceived loss of sequencing information when more a large fraction of data appears to be removed when the community with the greatest sequencing depth is rarefied to the size of the community with the least (e.g., `r paste0(loss$loss, "% with the ", loss$nice_name, " dataset")`). To assess the sensitivity of alpha and beta diversity metrics to rarefaction depth, I again used the dataset generated using the null models, but rarefied each community to varying sampling depths (Figure 6). The richness values increased with sampling effort as rare OTUs would continue be detected. In contrast, the Shannon diversity and Bray-Curtis values plateaued with increased sampling effort. This result was expected since increased sampling would lead to increased precision in the measured abundance of OTUs. Next, I measured the coefficient of variation (i.e., the mean divided by the standard deviation) between samples for richness, Shannon diversity, and Bray-Curtis distances. Although the richness values appeared to increased unbounded with smapling effort, the coefficient of variation for each dataset was relatively stable. In general, the coefficient of variation increased slightly with sampling depth only to decline once smaller samples were removed from the analysis at higher sampling depths. Interestingly, the coefficient of variation between Shannon diveristy values decreased towards zero with increased sampling effort and the coefficient of variation between Bray-Curtis distances tended to increased. Regardless, the coefficients of variation were relatively small.


***Most studies have a high level of sequencing coverage.*** To explore the concern over loss of sequencing depth further, I calculated the Good's coverage for the observed data. The median coverage for each dataset ranged between `r oxford_comma(obs_median$med)`% for the `r oxford_comma(capitalize(obs_median$dataset))` datasets, respectively (Figure 7). When I rarefied each dataset to the size of the smallest community in the dataset, with the exception of the `r oxford_comma(capitalize(rare_median$dataset))` datasets, the median coverage for the rarefied communities was still greater than 90%. These results suggest that most studies had a level of sequencing coverage that aligned with the diversity of the communities. Next, I used the null model for each dataset to ask how much sequencing effort was required to obtain higher levels of coverage. To obtain 95 and 99% coverage, an average of `r extrapolate$m` and `r extrapolate$n`-fold more sequence data was estimated to be required than was required to obtain 90% coverage, respectively (Figure 7). As suggested by the simulated coverages curve in Figure 7, these estimates are conservative. Regardless, the sequencing effort required to acheive higher sequencing depth would likely limit the number of samples that could be sequenced when controlling for costs. Although it may be disconcerting to rarefy to a sequencing depth that is considerably lower than that obtained for the best sequenced community in a dataset, sequencing coverage for many environments is probably adequate even at the lower sequencing depth. Of course, the results above have demonstrated that rarefaction is necessary to avoid problems with making inferences.


## Discussion

* Rarefy your data
* Problems with recommended methods...
  * Many recommended methods are borrowed from gened expression analysis
  * Meaning of zeroes in data - structural vs. below limit of detection
* Factors that determine what number of sequences to rarefy to
* Need better methods of pooling libraries that result in more even distribution of sequences across samples
* Rarefy your data


## Materials and Methods

**Choice of datasets.** The specific studies used in this study were selected because their data was publicly accessible through the Sequence Read Archive, the original investigators sequenced the V4 region of the 16S rRNA gene using paired 250 nt reads, and my previous familiarity with the data. The use of paired 250 nt reads to sequence the V4 region resulted in a near complete two-fold overap of the V4 region resulting in high quality contigs with a low sequencing error rate [@Kozich2013]. These data were processed through a standardized sequence curation pipeline to generate operational taxonomic units (OTUs) using the mothur software package [@Kozich2013; @Schloss2009]. OTUs were identified using the OptiClust algorithm to cluster sequences together that were not more than 3% different from each other [@Westcott2017].

**Null community model.** Null community models were generated such that within a dataset the number of sequences per sample and the number of sequences per OTU across all samples within the dataset were the same as was observed in original. This model effectively generated statistical samples of a single community so that there should not have been a statistical difference between the samples. This model implemented by randomly assigning each sequence in the dataset to an OTU and sample while keeping constant the number of sequences per sample and the total number of sequences in each OTU. This is a similar approach to that of the IS algorithm described by Ulrich and Gotelli [@Ulrich2010]. Because the construction of the null models was a stochastic process, 100 replicates were geneated for each dataset.

**Null treatment model.** I created an unbiased and biased treatment model. In the unbiased model, samples were randomly assigned to one of two treatment groups. In the biased treatment model, samples that had more than the median number of seqeunces for a dataset were assigned to one treatment group and the rest were assigned to a second treatment group. Comparison of any diversity metric across the two treatment groups should have only yielded a significant result in 5% of the simulations when testing under a Type I error (i.e., $\upalpha$) of 0.05. 

**Skewed abundance community model.** In the skewed abundance community model, communities were randomly assigned to one of two simulated treatment groups. Communities in the first treatment group were generated by calculating the relative abundance of each OTU across all samples and using those values as the probability of sampling each OTU. This probability distribution was sampled until each sample had the same number of sequences that it did in the observed data. Samples in the second treatment group were generated by adjusting the relative abundances of the OTUs in the firs treatment group by increasing the relative abundance of 10% of the OTUs by 5%. These values were determined after empirically searching for conditions that resulted in a large fraction of the randomizations yieleding a significant result across most of the studies. Sequences were sampled from the skewed community community until each sample had the same number of sequences that it did in the observed data. Under the skewed abundance community model each sample represented a statistical sampling of two communities such that there should not have been a statistically significant difference within a treatment group, but there was between the treatment groups. Because the construction of the skewed abundance community model was a stochastic process, 100 replicates were geneated for each dataset.

**Richness-adjusted community model.** In the richness-adjusted community model, communities were randomly assigned to one of two simulated treatment groups. Communities in the first treatment group were generated by calculating the relative abundance of each OTU across all samples and using those values as the probability of sampling each OTU. This probability distribution was sampled until each sample had the same number of sequences that it did in the observed data. Samples in the second treatment group were generated by removing 3% of the OTUs from the dataset and recalculating the relative abundance of the remaining OTUs. This percentage was determined after empirically searching for a value that resulted in a large fraction of the randomizations yieleding a significant result across most of the studies. Sequences were sampled from the richness-adjusted community distrubtion until each sample had the same number of sequences that it did in the observed data. Under the richness-adjusted community model each sample represented a statistical sampling of two communities such that there should not have been a statistically significant difference within a treatment group, but there was between the treatment groups. Because the construction of the richness-adjusted community model was a stochastic process, 100 replicates were geneated for each dataset.

**Alpha diversity calculations.** Various strategies for handling uneven sampling effort were evaluated to identify the best approach for calculating community richness and Shannon and inverse Simpson diversity indeices. Raw OTU counts were used as input to calculate sample richness and Shannon and inverse Simpson diversity using mothur [@Schloss2009; @Magurran2004]. Shannon diversity was calculated as

$$H_{shannon} = - \sum_{i=1}^{S_{obs}} \frac{n_i}{N} ln \frac{n_i}{N}$$

The Simpson diversity was calculated as

$$D_{simpson} = \frac {\sum_{i=1}^{S_{obs}} {n_i \left ( n_i - 1 \right )}}{N \left( N-1 \right )}$$

The inverse Simpson diversity was calculated as $1/D_{simpson}$. In both formulae, $n_i$ is the number of sequences in OTU $i$ and $N$ is the number of sequences in the sample. Rarefaction of richness, Shannon diversity and Inverse Simpson diversity values were carried out in mothur. Briefly, mothur calculates each value on a random draw of the same number of sequences from each sample and obtains a mean value based on 1,000 random draws. Scaled ranked subsampling (SRS) was used to normalize OTU counts to the size of the smallest sample in each dataset using the SRS R package (v.`r package_version("SRS")`)[@Beule2020]. Normalized OTU counts were used to calculate sample richness and Shannon and inverse Simpson diversity values using mothur. The non-parametric bias-corrected Chao1 and ACE richness estimators [@Chao2016] and a non-parametric estimator of the Shannon diversity [@Chao2003] were calculated using raw OTU counts with mothur. Parametric estimates of sample richness were calculated using the breakaway (BA) R package (v.`r package_version("breakaway")`)[@Willis2015]. The current analysis reports both the results from running default model selection procedure and the Poisson model. The default model selection returned either the Kemp, Negative Binomial, or Poisson models.

**Beta diversity calculations.** Similar to the alpha diversity calculations, multiple approaches were used to control for uneven sampling effort and calculate beta diversity. Raw and OTU counts were used for input to calculate the Jaccard, Bray-Curtis, and Euclidean dissimilarity indices using the vegdist function from the vegan R package (v.`r package_version("vegan")`)[@Oksanen2022]. The Jaccard index was calculated as

$$D_{Jaccard}=1-\frac{S_{AB}}{S_A+S_B-S_{AB}}$$

where $S_A$ and $S_B$ were the number of OTUs in samples $A$ and $B$ and $S_{AB}$ was the number of OTUs shared between the two samples. The Bray-Curtis index was calculated as 

$$D_{Bray-Curtis}=1-\frac{\sum_{i=1}^{S_T} \left| n_{A,i} - n_{B,i}\right| }{ N_A + N_B}$$

where $n_{A,i}$ and $n_{B,i}$ are the number of sequences observed in OTU $i$ from samples $A$ and $B$, respectively. $N_A$ and $N_B$ are the total number of sequences in samples $A$ and $B$, respectively. $S_T$ is the total number of OTUs observed between the two samples. The Euclidean distance was calculated as

$$D_{Euclidean}=1-\sqrt{\sum_{i=1}^{S_T}\left(n_{A,i} - n_{B,i}\right)^2}$$

These metrics were calculated using the relative abundance of each OTU using the vegdist function from vegan. The relative abundance was calculated as the number of sequences in the OTU (e.g., $n_{A,i}$) divided by the total number of sequences in the sample (e.g., $N_A$). Rarefied beta-diversity values were calculated using the avgdist function in vegan. Briefly, vegan's avgdist function calculates each pairwise dissimilarity index after obtaining a random draw of the same number of sequences from each sample. After obtaining 100 random draws it returns the mean value.

SRS normalized - Jaccard/BC
CSS normalized - Jaccard/BC
DeSeq2
Center-log ratio



**Power analysis.**
 The fraction of tests that yielded a significant test was a measure of the statistical power for the test. 


**Test of statistical significance.**
Wilcox, PERMANOVA



**Reproducible data analysis.** 
mothur - 1.47.0

***doi: 10.1038/nmeth.2658.*** Should CSS be used in alpha diversity analysis? No. The richness and shannon diversity values were no different from those obtained with the raw abundances. From the paper, "The relative proportion of the features is unaffected by the normalization". CSS paper refers to relative abundance approach as total-sum normalization (TSN)

Robust CLR - remove zero counts and calculate CLR
One CLR - add a pseudocount of 1 to all observations
Nudge CLR - add a pseudocount of 1/total number of sequences in sample
Zero CLR - Impute the value of zeroes using zCompositions package


***https://edepot.wur.nl/547087.*** "Log- ratio PCA is designed to give results that are library size- independent. However, as we demonstrated mathematically and with examples based on simulated and real data, log- ratio PCA becomes library size- dependent, if there are many infrequent taxa (many zeroes) and library sizes differ largely. In this situation, the row centring used in log- ratio PCA brings an effect of r (the row mean of the log- transformed counts) in the clr- transformed matrix. Note that this effect is irrespective of whether or not these infrequent taxa are genuine or due to sequencing noise or allocation error. This library size dependence is unexpected in the sense that, after applying the clr, the transformed matrix is free of the effect of the row totals for strictly positive data (yij>0 for all i and j). We additionally demonstrate that library size variability causes a loss in power in detecting an effect of x with log- ratio RDA. If there is additionally a correlation between treatment and the library size, the type 1 error for detecting the effect of x can be seriously inflated."

***https://www.nature.com/articles/s41522-020-00160-w.*** "An important characteristic of a feature table is that it is typically sparse, sometimes as many as ~90% are zero entries21, which creates a challenge for analyzing rare taxa. A quick and simple strategy to deal with excess zeros is to add a small positive constant (e.g. 1) called pseudo-count14,22 to each cell of the feature table. The addition of a pseudo-count becomes necessary when using methods of analysis that require log transformation of the observed counts. Even though adding a pseudo-count is simple and widely used, the choice of the pseudo-count is ad hoc. Studies have shown that differential abundance or clustering results could be sensitive to the choice of pseudo count23,24. Although different values of pseudo counts have been discussed in the literature23,24,25,26, to the best of our knowledge, there is no consensus on how to choose the optimal value. Other strategies involve modeling zero counts by some probability models21,27."



https://academic.oup.com/bioinformatics/article/34/16/2870/4956011
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6755255/
\vspace{10mm}

**Acknowledgements.** 

\newpage

## References

\setlength{\parindent}{-0.25in}
\setlength{\leftskip}{0.25in}
\noindent

<div id="refs"></div>
\bibliography{ref}
\setlength{\parindent}{0in}
\setlength{\leftskip}{0in}

\newpage

**Table 1. Summary of studies used in the analysis.** For all studies, the number of sequences used from each dataset was rarefied to the smallest sample size. A graphical represenation of the distribution of sample sizes for each dataset and the samples that were removed from each dataset are provided in Figure S1.

\small

```{r results_f}
table_1 %>%
  arrange(nice_name) %>%
  mutate(
    nice_name = glue("{nice_name}\\ {reference}"),
    total_seqs=format(total_seqs, big.mark=",", trim=TRUE),
    median=format(as.integer(median), big.mark=",", trim=TRUE),
    min=format(min, big.mark=",", trim=TRUE),
    max=format(max, big.mark=",", trim=TRUE),
    range = glue("{min}\\Hyphdash*{max}"),
    n_samples = n_samples) %>%
  select(nice_name, n_samples, total_seqs, median, range, sra_study) %>%
  kableExtra::kable(format="markdown", booktabs=TRUE, escape=F, align="lrrrrr",
    linesep="",
    col.names = linebreak(
      c(
        "\\textbf{Dataset\\nobreakspace{}(Ref)}",
        "\\textbf{Samples}",
        "\\textbf{Total}\n\\textbf{sequences}",
        "\\textbf{Median}\n\\textbf{sequences}",
        "\\textbf{Range of}\n\\textbf{sequences}",
        "\\textbf{SRA study}\n\\textbf{accession}"
      ),
      align="c")
  )
```
\normalsize

\newpage

## Figures

\newpage

\includegraphics[height=17cm]{figure_1.png}

**Figure 1. Rarefaction eliminates the correlation between sequencing depth and alpha diversity (A) and between differences in sampling depth and beta (B) diversity metrics when using null community models.** Examples of the relationship between different metrics and methods for controlling for uneven sequencing effort are provided in Figures S2 and S3 for alpha and beta diversity metrics, respectively. Each point represents the mean of 100 random null community models; the standard deviation was smaller than the size of the plotting symbol.

\newpage

\includegraphics[height=17cm]{figure_2.png}

**Figure 2. The risk of falsely detecting a difference between treatment groups drawn from a null model does not meaningfully vary from 5%, regardless of approach for controlling for uneven sequencing depth**. Samples were randomly assigned to different treatment groups. To calculate the false detection rate, datasets were regenerated 100 times and differences in alpha diversity were tested using a Wilcoxon test (A) and differences in beta diversity were tested using PERMANOVA (B) at a 5% threshold. The false positive rate was the number of times a dataset yeilded a significant result.

\newpage

\includegraphics[height=17cm]{figure_3.png}

**Figure 3.The risk of falsely detecting a difference between treatment groups drawn from a null model does not meaningfully vary from 5% when data are rarefied when sequencing depth is confounded with treatement group**. Samples were assigned to different treatment groups based on whether they were above the median number of sequences for each dataset. To calculate the false detection rate, datasets were regenerated 100 times and differences in alpha diversity were tested using a Wilcoxon test (A) and differences in beta diversity were tested using PERMANOVA (B) at a 5% threshold. The false positive rate was the number of times a dataset yeilded a significant result.


\newpage

\includegraphics[height=17cm]{figure_4.png}

**Figure 4. The ability to detect true differences in treatment groups for alpha (A) and beta (B) diversity metrics is greatest when communities differing in the relative abundance of their OTUs are rarefied.** For each dataset samples were randomly assigned to one of two community distributions where the abundance of OTUs differed. To calculate the power for each datasets, datasets were regenerated 100 times and differences in alpha diversity were tested using a Wilcoxon test (A) and differences in beta diversity were tested using PERMANOVA (B) at a 5% threshold. The power was the number of times a dataset yielded a significant result.


\newpage

\includegraphics{figure_5.png}

**Figure 5. The ability to detect true differences in treatment groups for alpha diversity metrics is greatest when communities differing in richness are rarefied.** For each dataset samples were randomly assigned to one of two community distributions where one distribution contained a subset of OTUs found in the other. To calculate the power for each dataset, datasets were regenerated 100 times and differences in alpha diversity were tested using a Wilcoxon test (A) and differences in beta diversity were tested using PERMANOVA (B) at a 5% threshold. The power was the number of times a dataset yielded a significant result. 


\newpage

\includegraphics{figure_6.png}

**Figure 6. The mean and coefficient of variation for rarefied richness, shannon diversity, and Bray-Curtis dissimilarity vary with sequencing depth.** For each dataset, a null community distribution was created and samples were created to have the same sequencing depth as they did originally. The placement of the plotting symbol indicates the size of the smallest sample. Results are only shown for sequencing depths where a dataset had 5 or more samples.

\newpage

\includegraphics{figure_7.png}

**Figure 7. Most datasets are sequenced to a level that provides a high level of coverage.** Each plotting symbol represents the observed Good's coverage for a different sample in each dataset. The smoothed line indicates the simulated coverage for varying levels of sampling effort when a null community is generated from the observed data. The box and whisker plot indicates the range of coverage values when the observed commmunity data were rarefied to the size of the least sequenced sample.

\newpage

\includegraphics{figure_s1.png}

**Figure S1. The number of sequences observed in each sample for each dataset included in this analysis generally varied by 10 to 100-fold.** The threshold for specifying the number of sequences per sample varied by dataset and was determined based on identifying natural breaks in the data.

\newpage

\includegraphics{figure_s2.png}

**Figure S2. Examples of the richness in each of the 490 samples that were generated for one randomization of the null model using the human dataset.** The x-axis indicates the number of sequences in each of the samples prior to each method's appraoch of controlling for uneven sampling effort. The Spearman correlation coefficient ($\uprho$) and test of whether the coefficient was significantly different from zero are indicated for each panel.

\newpage

\includegraphics{figure_s3.png}

**Figure S3. Examples of differences in beta diversity in each of the 490 samples that were generated for one randomization of the null model using the human dataset.** The x-axis indicates the difference in the number of sequences in each of the samples that went into calcualting the pairwise distance prior to each method's appraoch of controlling for uneven sampling effort. The Spearman correlation coefficient ($\uprho$) and test of whether the coefficient was significantly different from zero are indicated for each panel.
