---
bibliography: references.bib
output:
  pdf_document:
    keep_tex: true
csl: asm.csl
geometry: margin=1.0in
header-includes:
 - \usepackage{booktabs}
 - \usepackage{longtable}
 - \usepackage{array}
 - \usepackage{multirow}
 - \usepackage{wrapfig}
 - \usepackage{float}
 - \usepackage{colortbl}
 - \usepackage{pdflscape}
 - \usepackage{tabu}
 - \usepackage{threeparttable}
 - \usepackage{threeparttablex}
 - \usepackage[normalem]{ulem}
 - \usepackage{makecell}
 - \usepackage{setspace}
 - \doublespacing
 - \usepackage[left]{lineno}
 - \linenumbers
 - \modulolinenumbers
 - \usepackage{helvet} % Helvetica font
 - \renewcommand*\familydefault{\sfdefault} % Use the sans serif version of the font
 - \usepackage[T1]{fontenc}
 - \usepackage[shortcuts]{extdash}
---


```{r, echo=FALSE}
options(tidyverse.quiet = TRUE)
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(kableExtra))
suppressPackageStartupMessages(library(glue))

opts_chunk$set("tidy" = TRUE)
opts_chunk$set("echo" = FALSE)
opts_chunk$set("eval" = TRUE)
opts_chunk$set("warning" = FALSE)
opts_chunk$set("message" = FALSE)
opts_chunk$set("cache" = FALSE)

inline_hook <- function(x, digits=2){

  if(is.list(x)){
    x <- unlist(x)
  }
  if(is.numeric(x)){
      paste(format(x,big.mark=',', digits=digits, nsmall=digits, scientific=FALSE))
  } else {
      paste(x)
  }
}
knitr::knit_hooks$set(inline=inline_hook)

package_version <- function(package){

  paste(unlist(packageVersion(package)), collapse='.')

}


oxford_comma <- function(x, digits=2) {

  x <- map_chr(x, inline_hook, digits=digits)

  if(length(x) < 2){
    x
  } else if(length(x) == 2){
    paste(x, collapse = " and ")
  } else {
    paste(paste(x[-length(x)], collapse=", "), x[length(x)], sep=", and ")
  }
}
```

# Rarefy your data


\vspace{20mm}

**Running title:** Rarefy your data

\vspace{20mm}

Patrick D. Schloss${^\dagger}$

\vspace{40mm}

${\dagger}$ To whom corresponsdence should be addressed:


\href{mailto:pschloss@umich.edu}{pschloss@umich.edu}

Department of Microbiology & Immunology

University of Michigan

Ann Arbor, MI 48109

\vspace{20mm}

**Research article**

\newpage

```{r datasets}
table_1 <- read_tsv(here('data/process/study_summary_statistics.tsv'))

n_sample_range <- table_1 %>%
  pull(n_samples) %>%
  range() %>% as.integer()

n_med_sequence_range <- table_1 %>%
  pull(median) %>%
  range() %>% as.integer()

low_fold_samples <- table_1 %>%
  filter(fold_difference < 2) %>%
  pull(directory)

high_fold_range <- table_1 %>%
  filter(fold_difference >= 2) %>%
  pull(fold_difference) %>%
  range() %>%
  round(digits=1)
```


## Abstract



## Importance



\newpage

## Introduction

* Motivation
  * Problem of uneven sampling effort
* What is rarefaction? History, reason for rarefaction
  * Repeated down sampling of datasets to a common number of observations to calculate the average value to ascertain the expected value of a metric for the metric under study; typically richness
  * Control for unneven sampling effort
  * Methods vary in their sensitivity to uneven sampling
* Reasons behind "rarefaction is inadmissable"
  * Weird simulation
* Alternative approaches and claims
  * sampling invariance
* Goal of this study



## Results

***Choice of datasets.*** I selected 16S rRNA gene sequence data from from 12 studies that characterized the variation in bacterial communities from diverse environments (Table 1). The specific studies were selected because their data was publicly accessible through the Sequence Read Archive, the original investigators sequenced the V4 region of the 16S rRNA gene using paired 250 nt reads, and my previous familiarity with the data. The use of paired 250 nt reads to sequence the V4 region resulted in a near complete two-fold overap of the V4 region resulting in high quality contigs with a low sequencing error rate [@Kozich2013]. These data were processed through the standard sequence curation pipeline to generate operational taxonomic units (OTUs) using the mothur software package [@Kozich2013; @Schloss2009]. The original studies generated the sequence data by pooling separate PCR products that were generated by amplifying the V4 region of the 16S rRNA gene from the bacterial DNA in multiple samples. Because pooling equimolar quantities of DNA is frought with difficulties, it was common to observe wide variation in the number of sequences in each sample (Figure S1).


***Without rarefaction, metrics of alpha diversity are sensitive to sampling effort.*** To test the sesitivity of various approaches of measuring alpha diversity to sampling effort, I generated null models for each study. Under a null model, each sample from the same study would be expected to have the same alpha diversity regardless of the sampling effort. I assessed richness without any correction, using normalized OTU counts, with estimates based on non-parametric and parametric approaches, and using rarefaction. For each study, all of the approaches, except for rarefaction, showed a strong correlation between richness and the number of sequences in the sample (Figure 1A). Next, I assessed diversity using the Shannon diversity index and the inverse Simpson diversity index without any correction, using normalized OTU counts, and rarefaction; I also used a non-parametric estimator of Shannon diversity. The correlation between sampling depth and the diversity metric was not as strong as it was for richness and the inverse Simpson diversity values were less sensitive than the Shannon diversity values; however, the correlation to the rarefied diversity metrics were the lowest for all of the metrics and studies (Figure 1B). The rarefied alpha-diversity metrics consistently demonstrated a lack of sensitivity to sampling depth.


***Without rarefaction, metrics of beta diversity are sensitive to sampling effort.*** To test the sesitivity of various approaches of measuring beta diversity to sampling effort, I used the same null models used for studying the sensitivity of alpha diversity. Under a null model, the ecological distance between any pair of samples would be the same regardless of the difference in the number of sequences observed in each sample. First, I analyzed the sensitivity of the Jaccard distance coefficient, which incorporates whether an OTU is present in each community and not their relative abundance. When calculating Jaccard distances using the uncorrected OTU counts, normalized OTU counts, relative abundances, and rarefaction only the rarefied data showed a lack of sensitivity to sampling effort (Figure 2A). Second, I analyzed the sensitivity of the Bray-Curtis distance coefficient, which is a popular metric that incorporates the abundance of each OTU. Similar to what I observed with the Jaccard coefficient, only the rarefied data showed a lack of sensitivity to sampling effort (Figure 2B). Third, I calcualted Aitchison distances on raw OTU counts where the central log-ratio (CLR) was calculated by ignoring OTUs in samples with zero counts (robust CLR), adding a pseudocount of 1 to all OTU counts prior to calculating the CLR (one CLR), XXXXX XXXXX XXXXX XXXXX XXXXX XXXXX XXXXX XXXXX XXXXX XXXXX XXXXXXXXXX (n CLR), and imputing the value of zero counts (z CLR). Regardless of the approach, the Aitchison distances were all strongly sensitive to sampling effort (Figure 2C). Finally, I used the cumulative sum scaling (CSS) normalization from metagenomeSeq and variance stabilization technique (VST) from DeSeq2 prior to calculating Euclidean distances. Both approachs revealed a strong sensitivity to sampling effort (Figure 2D). Although Euclidean distances are not typically used on raw or rarefied count data in ecology, rarefied Euclidean distances were not sensitive to sampling effort. Across each of the beta diversity metrics and approaches used to account for uneven sampling effort and sparsity, rarefaction was the least sensitive approach to differences in sampling effort.


***Rarefaction limits the detection of false positives when sampling effort and treatment group are confounded.*** Next, I investigated the impact of the various strategies and metrics on falsely detecting a significant diffeerence using the the same communities generated from the null model in the analysis of alpha and beta diversity metrics. To test for differences in alpha and beta diversity I used the non-parametric Wilcoxon test and non-parametric permutation-based multivariate analysis of variance (PERMANOVA). First, within each study, I randomly assigned each sample to one of two treatment groups. My expectation was that approximately 5 of the 100 (5%) random tests for each comparison would yield a significant test result. Indeed, for each study and alpha and beta diversity metric and strategy for accounting for uneven sampling, approximately 5% of the tests yielded a significant result (Figure 3). Second, within each study, I assigned samples with more than the median number of sequences per sample to one treatment group and the rest to another treatment group. If there is no sensitivity to sampling effort, I would again expect that 5% of the tests would yield a significant result. In fact, only the rarefied data consistently resulted in a 5% false positive rate for alpha and beta diversity metrics (Figure 4). These results align with the observed sensitivity of alpha and beta diversity metrics to sampling effort and underscore the value of rarefaction.


***Rarefaction preserves the statistical power to detect differences between treatment groups.*** To assess the impact of different approaches to control for uneven sampling effort I performed two additional simulations. In the first simulation, for each study samples were randomly assigned to one of two treatment groups. Samples in the first treatment group were generated by sampling from the null distribution. Samples in the second treatment group were generated by perturbing the null distribution by increasing the relative abundance of 10% of the OTUs by 5%. These values were determined after empirically searching for conditions that resulted in a large fraction of the randomizations yieleding a significant result across most of the studies. The fraction of tests that yielded a significant test was a measure of the statistical power for the test. Relative to the rarefied data, the power to detect differences in alpha and beta diversity was considerably lower for each of the strategies for handling uneven sampling effort. The power to detect differences in richness by all approaches was low (Figures 7 and 8). This was likely because the approach to generating the second community did not necessarily change the number of OTUs in each treatment group. To explore this further, in the second simulation the second treatment group was perturbed by removing 3% of the OTUs from the model. Again, the rarefied data had a considerably higher statistical power than the other approaches when measuring richness (Figure 9). Both simulations highlight the value of rarefaction for preserving the statistical power to detect differences between treatment groups for measures of alpha and beta diversity.


***Increased rarefaction depth reduces intra-sample variation in alpha and beta diversity.*** To assess the sensitivity of alpha and beta diversity metrics to rarefaction depth, I again used the dataset generated using the null models and rarefied them to varying depths. For the alpha diversity metrics, the value of the metrics plateaued and the coefficient of variation (i.e., the mean divided by the standard deviation) between samples remained constant as the rarefaction depth increased (Figure 10). For beta diversity metrics, the distance between samples and the coefficient of variation between samples decreased as sampling depth increased (Figure 11). These results confirm that greater sequencing depth provides a more robust estimate of the metrics.


***Most studies have a high level of sequencing coverage.*** I calculated the Good's coverage for the observed data and found that each of the studies had a minimum coverage greater than 90% at their lowest sequencing depth (Figure 12A). This suggests that most studies have a high level of sequencing coverage. Next, I returned to the null models to ask how much sequencing effort was required to obtain higher levels of coverage. To obtain 95 and 99% coverage, an average of XX and XX-fold more sequence data was required, respectively (Figure 12B). Although it is clear that most researchers would desire greater coverage, the sequencing effort required to acheive that sequencing depth would likely limit the number of samples that could be sequenced when controlling for costs.


***Evidence that not rarefying data can impact results in original studies.*** To assess the impact of using alternatives to rarefaction, I reassessed hypotheses from the human, mice, and peromyscus studies. These studies were selected because they originated from my research group and I know the datasets well. First, the study that published the human dataset was interested in the difference in the fecal microbial communities of patients with and without colorectal cancer. Here, I divided the patients into peope with and without screen relevant neoplasia (SRN). Among the alpha diversity metrics, the test were non-significant with similar effect sizes; however, the richness estimates obtained using parametric appraoches detected statistically significant differences in richness. Although the tests using Bray-Curtis distances were significant regardless of whether rarefaction was used, the effect sizes were smaller for the distances calculated using the CLR, VST, CSS transformations.


* Human study: Did not alter effect size or significance of alpha or beta diversity, but did result in reduced effect sizes for measures of richness and non-parametric estimators of richness; breakaway detected a difference 

Mouse

Peromyscus




## Discussion

* Rarefy your data
* Problems with recommended methods...
  * Many recommended methods are borrowed from gened expression analysis
  * Meaning of zeroes in data - structural vs. below limit of detection
* Factors that determine what number of sequences to rarefy to
* Need better methods of pooling libraries that result in more even distribution of sequences across samples
* Rarefy your data


## Materials and Methods

**Null models.** Null models were generated by randomly assigning each sequence in the study to an OTU and sample while keeping constant the number of sequences per sample and the total number of sequences in each OTU. Because the construction of the null models was a stochastic process, 100 replicates were geneated for each study.


**Data availability.** 

**Reproducible data analysis.** 


\vspace{10mm}

**Acknowledgements.** 

\newpage

## References

\setlength{\parindent}{-0.25in}
\setlength{\leftskip}{0.25in}
\noindent

<div id="refs"></div>
\bibliography{ref}
\setlength{\parindent}{0in}
\setlength{\leftskip}{0in}

\newpage

**Table 1. Summary of studies used in the analysis.** For all studies, the number of sequences used from each study was rarefied to the smallest sample size. A graphical represenation of the distribution of sample sizes for each study and the samples that were removed from each study are provided in Figure S1.

\small

```{r results_f}
table_1 %>%
  arrange(nice_name) %>%
  mutate(
    nice_name = glue("{nice_name}\\ {reference}"),
    total_seqs=format(total_seqs, big.mark=",", trim=TRUE),
    median=format(as.integer(median), big.mark=",", trim=TRUE),
    min=format(min, big.mark=",", trim=TRUE),
    max=format(max, big.mark=",", trim=TRUE),
    range = glue("{min}\\Hyphdash*{max}"),
    n_samples = n_samples) %>%
  select(nice_name, n_samples, total_seqs, median, range, sra_study) %>%
  kableExtra::kable(format="markdown", booktabs=TRUE, escape=F, align="lrrrrr",
    linesep="",
    col.names = linebreak(
      c(
        "\\textbf{Study\\nobreakspace{}(Ref)}",
        "\\textbf{Samples}",
        "\\textbf{Total}\n\\textbf{sequences}",
        "\\textbf{Median}\n\\textbf{sequences}",
        "\\textbf{Range of}\n\\textbf{sequences}",
        "\\textbf{SRA study}\n\\textbf{accession}"
      ),
      align="c")
  )
```
\normalsize

\newpage


**Figure 1.**

\newpage

**Figure S1.**
